{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "510f3247",
   "metadata": {},
   "source": [
    "## Graph transformer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8cb65381",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import numpy as np\n",
    "from sklearn.manifold import TSNE\n",
    "import matplotlib.pyplot as plt\n",
    "import os\n",
    "import urllib\n",
    "import tarfile\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "17b0cd8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- DEVICE SETUP ---\n",
    "# Automatically detect and use the MPS device on Apple Silicon\n",
    "if torch.backends.mps.is_available():\n",
    "    device = torch.device(\"mps\")\n",
    "elif torch.cuda.is_available():\n",
    "    device = torch.device(\"cuda\")\n",
    "else:\n",
    "    device = torch.device(\"cpu\")\n",
    "print(f\"Using device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98618d07",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Download and extract if not present\n",
    "if not os.path.exists(\"cora\"):\n",
    "    print(\"Downloading Cora dataset...\")\n",
    "    urllib.request.urlretrieve(\n",
    "        \"https://linqs-data.soe.ucsc.edu/public/lbc/cora.tgz\", \"cora.tgz\"\n",
    "    )\n",
    "    with tarfile.open(\"cora.tgz\", \"r:gz\") as tar:\n",
    "        tar.extractall()\n",
    "\n",
    "# Load node features and labels (cora.content)\n",
    "content_path = \"cora/cora.content\"\n",
    "content = np.genfromtxt(content_path, dtype=str)\n",
    "\n",
    "# Load edge list (cora.cites)\n",
    "cites_path = \"cora/cora.cites\"\n",
    "cites = np.genfromtxt(cites_path, dtype=int)\n",
    "\n",
    "# 1. Map original paper IDs to contiguous integer indices (0 to N-1)\n",
    "paper_ids = content[:, 0]\n",
    "id_to_idx = {int(p_id): i for i, p_id in enumerate(paper_ids)}\n",
    "N = len(paper_ids)  # Number of nodes\n",
    "\n",
    "# 2. Extract Features (Bag-of-Words)\n",
    "# Move features tensor to the selected device\n",
    "features = torch.tensor(content[:, 1:-1].astype(np.float32)).to(device)\n",
    "D = features.size(1)  # Feature dimension\n",
    "\n",
    "# 3. Extract and Encode Labels\n",
    "labels_text = content[:, -1]\n",
    "# Map text labels to integer indices (0 to C-1)\n",
    "label_map = {name: i for i, name in enumerate(np.unique(labels_text))}\n",
    "labels = np.array([label_map[name] for name in labels_text])\n",
    "# Move labels tensor to the selected device\n",
    "labels = torch.tensor(labels, dtype=torch.long).to(device)\n",
    "C = len(label_map)  # Number of classes\n",
    "class_names = list(label_map.keys())  # For visualization legend\n",
    "\n",
    "# 4. Process Edges and Symmetrize\n",
    "source_nodes = np.array([id_to_idx[src] for src in cites[:, 0]])\n",
    "target_nodes = np.array([id_to_idx[tgt] for tgt in cites[:, 1]])\n",
    "\n",
    "# Ensure tensors for stacking\n",
    "source_tensor = torch.tensor(source_nodes, dtype=torch.long)\n",
    "target_tensor = torch.tensor(target_nodes, dtype=torch.long)\n",
    "\n",
    "edge_index = torch.stack([source_tensor, target_tensor], dim=0)\n",
    "\n",
    "# Symmetrize edges\n",
    "reversed_edges = torch.stack([target_tensor, source_tensor], dim=0)\n",
    "edge_index = torch.cat([edge_index, reversed_edges], dim=1)\n",
    "edge_index = torch.unique(edge_index, dim=1)\n",
    "\n",
    "\n",
    "# 5. Create Adjacency Matrix and Attention Mask\n",
    "def to_dense_adj(edge_index, num_nodes, device):\n",
    "    # Create the adjacency matrix directly on the target device\n",
    "    adj = torch.zeros(num_nodes, num_nodes, dtype=torch.float, device=device)\n",
    "    # Ensure edge_index is on CPU before indexing if adj is on a GPU/MPS device\n",
    "    adj[edge_index[0].to(device), edge_index[1].to(device)] = 1.0\n",
    "    return adj\n",
    "\n",
    "\n",
    "# Create adjacency and mask on the selected device\n",
    "adj = to_dense_adj(edge_index, N, device)\n",
    "adj = adj + torch.eye(N, device=device)  # Add self-loops\n",
    "# Create mask (non-neighbors = -inf) on the selected device\n",
    "attention_mask = (adj == 0).float() * (-1e9)\n",
    "\n",
    "\n",
    "# 6. Create Standard Planetoid Masks\n",
    "# Move masks to the selected device\n",
    "train_mask = torch.zeros(N, dtype=torch.bool, device=device)\n",
    "val_mask = torch.zeros(N, dtype=torch.bool, device=device)\n",
    "test_mask = torch.zeros(N, dtype=torch.bool, device=device)\n",
    "\n",
    "train_mask[:140] = True\n",
    "val_mask[140 : 140 + 500] = True\n",
    "test_mask[140 + 500 : 140 + 500 + 1000] = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b206ae9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 2. Pure PyTorch Graph Transformer Implementation (No change needed here) ---\n",
    "\n",
    "\n",
    "class AttentionHead(nn.Module):\n",
    "    def __init__(self, in_features, head_out_features):\n",
    "        super().__init__()\n",
    "        self.W_q = nn.Linear(in_features, head_out_features, bias=False)\n",
    "        self.W_k = nn.Linear(in_features, head_out_features, bias=False)\n",
    "        self.W_v = nn.Linear(in_features, head_out_features, bias=False)\n",
    "        self.D_k = head_out_features**0.5\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        Q = self.W_q(x)\n",
    "        K = self.W_k(x)\n",
    "        V = self.W_v(x)\n",
    "        scores = torch.matmul(Q, K.transpose(0, 1)) / self.D_k\n",
    "        scores = scores + mask  # Apply Graph Mask\n",
    "        attention_weights = F.softmax(scores, dim=1)\n",
    "        output = torch.matmul(attention_weights, V)\n",
    "        return output\n",
    "\n",
    "\n",
    "class MultiHeadAttention(nn.Module):\n",
    "    def __init__(self, in_features, n_heads, head_out_features):\n",
    "        super().__init__()\n",
    "        self.heads = nn.ModuleList(\n",
    "            [AttentionHead(in_features, head_out_features) for _ in range(n_heads)]\n",
    "        )\n",
    "        self.linear_proj = nn.Linear(n_heads * head_out_features, in_features)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        outputs = [head(x, mask) for head in self.heads]\n",
    "        concat_output = torch.cat(outputs, dim=-1)\n",
    "        output = self.linear_proj(concat_output)\n",
    "        return output\n",
    "\n",
    "\n",
    "class GraphTransformerLayer(nn.Module):\n",
    "    def __init__(self, in_features, n_heads, head_out_features, dropout_rate=0.1):\n",
    "        super().__init__()\n",
    "        self.mha = MultiHeadAttention(in_features, n_heads, head_out_features)\n",
    "        self.norm1 = nn.LayerNorm(in_features)\n",
    "        self.dropout1 = nn.Dropout(dropout_rate)\n",
    "\n",
    "        self.ffn = nn.Sequential(\n",
    "            nn.Linear(in_features, in_features * 4),\n",
    "            nn.ReLU(),\n",
    "            nn.Dropout(dropout_rate),\n",
    "            nn.Linear(in_features * 4, in_features),\n",
    "        )\n",
    "        self.norm2 = nn.LayerNorm(in_features)\n",
    "        self.dropout2 = nn.Dropout(dropout_rate)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x_attn = self.mha(x, mask)\n",
    "        x = x + self.dropout1(x_attn)\n",
    "        x = self.norm1(x)\n",
    "\n",
    "        x_ffn = self.ffn(x)\n",
    "        x = x + self.dropout2(x_ffn)\n",
    "        x = self.norm2(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class GraphTransformer(nn.Module):\n",
    "    \"\"\"\n",
    "    The complete Graph Transformer Model, modified to return intermediate embeddings.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(\n",
    "        self,\n",
    "        in_features,\n",
    "        hidden_dim,\n",
    "        out_classes,\n",
    "        n_layers,\n",
    "        n_heads,\n",
    "        head_out_features,\n",
    "        dropout_rate=0.1,\n",
    "    ):\n",
    "        super().__init__()\n",
    "        self.input_proj = nn.Linear(in_features, hidden_dim)\n",
    "        self.layers = nn.ModuleList(\n",
    "            [\n",
    "                GraphTransformerLayer(\n",
    "                    hidden_dim, n_heads, head_out_features, dropout_rate\n",
    "                )\n",
    "                for _ in range(n_layers)\n",
    "            ]\n",
    "        )\n",
    "        self.output_proj = nn.Linear(hidden_dim, out_classes)\n",
    "\n",
    "    def forward(self, x, mask):\n",
    "        x = F.relu(self.input_proj(x))\n",
    "\n",
    "        for layer in self.layers:\n",
    "            x = layer(x, mask)\n",
    "\n",
    "        # Store or return the final embeddings (x) before the classifier\n",
    "        final_embeddings = x\n",
    "\n",
    "        # Classification output\n",
    "        classification_output = self.output_proj(x)\n",
    "\n",
    "        # Return both the classification output and the hidden embeddings\n",
    "        return F.log_softmax(classification_output, dim=1), final_embeddings\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "84b82d9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# --- 3. Model Initialization and Training ---\n",
    "\n",
    "# Hyperparameters\n",
    "HIDDEN_DIM = 64\n",
    "N_HEADS = 8\n",
    "HEAD_OUT_FEATURES = 8\n",
    "N_LAYERS = 2\n",
    "DROPOUT = 0.6\n",
    "LR = 0.005\n",
    "EPOCHS = 200\n",
    "\n",
    "# Initialize Model and move it to the selected device\n",
    "model = GraphTransformer(\n",
    "    in_features=D,\n",
    "    hidden_dim=HIDDEN_DIM,\n",
    "    out_classes=C,\n",
    "    n_layers=N_LAYERS,\n",
    "    n_heads=N_HEADS,\n",
    "    head_out_features=HEAD_OUT_FEATURES,\n",
    "    dropout_rate=DROPOUT,\n",
    ").to(device)\n",
    "\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=LR, weight_decay=5e-4)\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train(model, x, mask, y, train_mask, optimizer):\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "    # out[0] is classification output, out[1] is embeddings\n",
    "    out, _ = model(x, mask)\n",
    "    loss = F.nll_loss(out[train_mask], y[train_mask])\n",
    "    # For MPS/CUDA, ensure all gradients are processed before calling step()\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "# Evaluation function\n",
    "@torch.no_grad()\n",
    "def test(model, x, mask, y, test_mask):\n",
    "    model.eval()\n",
    "    out, _ = model(x, mask)\n",
    "    pred = out.argmax(dim=1)\n",
    "    correct = pred[test_mask].eq(y[test_mask]).sum().item()\n",
    "    acc = correct / test_mask.sum().item()\n",
    "    return acc\n",
    "\n",
    "\n",
    "# --- 4. Main Execution and Visualization ---\n",
    "\n",
    "print(f\"Starting training on Cora dataset (Nodes: {N}, Features: {D}, Classes: {C})...\")\n",
    "best_val_acc = 0.0\n",
    "best_test_acc = 0.0\n",
    "\n",
    "for epoch in range(1, EPOCHS + 1):\n",
    "    loss = train(model, features, attention_mask, labels, train_mask, optimizer)\n",
    "    val_acc = test(model, features, attention_mask, labels, val_mask)\n",
    "    current_test_acc = test(model, features, attention_mask, labels, test_mask)\n",
    "\n",
    "    if val_acc > best_val_acc:\n",
    "        best_val_acc = val_acc\n",
    "        best_test_acc = current_test_acc\n",
    "\n",
    "    if epoch % 50 == 0 or epoch == EPOCHS:\n",
    "        print(\n",
    "            f\"Epoch: {epoch:03d}, Loss: {loss:.4f}, Val Acc: {val_acc:.4f}, Test Acc: {current_test_acc:.4f}\"\n",
    "        )\n",
    "\n",
    "print(f\"\\n--- Training Complete ---\")\n",
    "print(f\"Best Test Accuracy (based on max validation accuracy): **{best_test_acc:.4f}**\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7c8f8fb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualization function\n",
    "def visualize_embeddings(embeddings, labels, class_names, title):\n",
    "    print(\n",
    "        f\"\\n--- Running t-SNE for Visualization (N={embeddings.shape[0]}, D={embeddings.shape[1]}) ---\"\n",
    "    )\n",
    "\n",
    "    # Run t-SNE to reduce high-dimensional embeddings (N, D_hidden) to (N, 2)\n",
    "    tsne = TSNE(n_components=2, random_state=42, perplexity=30)\n",
    "    embeddings_2d = tsne.fit_transform(embeddings)\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "\n",
    "    # Get unique labels and create a color map\n",
    "    unique_labels = np.unique(labels)\n",
    "    colors = plt.cm.get_cmap(\"viridis\", len(unique_labels))  # Use 'viridis' colormap\n",
    "\n",
    "    # Scatter plot each class separately for a legend\n",
    "    for i, label in enumerate(unique_labels):\n",
    "        indices = labels == label\n",
    "        plt.scatter(\n",
    "            embeddings_2d[indices, 0],\n",
    "            embeddings_2d[indices, 1],\n",
    "            c=[colors(i)],\n",
    "            label=class_names[label],\n",
    "            s=20,\n",
    "            alpha=0.7,\n",
    "            edgecolors=\"w\",\n",
    "            linewidths=0.5,\n",
    "        )\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.legend(title=\"Research Area\")\n",
    "    plt.xlabel(\"t-SNE Dimension 1\")\n",
    "    plt.ylabel(\"t-SNE Dimension 2\")\n",
    "    plt.grid(True, linestyle=\"--\", alpha=0.5)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c4f1d33d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get the final embeddings and labels for visualization\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    _, final_embeddings_tensor = model(features, attention_mask)\n",
    "\n",
    "# Move tensors back to CPU and convert to numpy for non-PyTorch libraries (t-SNE and Matplotlib)\n",
    "final_embeddings_np = final_embeddings_tensor.cpu().numpy()\n",
    "labels_np = labels.cpu().numpy()\n",
    "\n",
    "# Run Visualization\n",
    "visualize_embeddings(\n",
    "    final_embeddings_np,\n",
    "    labels_np,\n",
    "    class_names,\n",
    "    \"t-SNE Visualization of Node Embeddings (Graph Transformer on Cora)\",\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cop-gnn-py3.12 (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
