{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2   "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Node2vec\n",
    "\n",
    "https://arxiv.org/abs/1607.00653\n",
    "\n",
    "https://pytorch-geometric.readthedocs.io/en/latest/tutorial/shallow_node_embeddings.html\n",
    "\n",
    "https://spotintelligence.com/2024/01/18/node2vec/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| device: 'mps'\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import networkx as nx\n",
    "import numpy as np\n",
    "from icecream import ic\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "import torch.optim as optim\n",
    "\n",
    "import random\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "\n",
    "device = \"mps\" if torch.backends.mps.is_available() else \"cpu\"\n",
    "ic(device);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch._C.Generator at 0x117207090>"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Set seeds for reproducibility\n",
    "random.seed(42)\n",
    "np.random.seed(42)\n",
    "torch.manual_seed(42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the Zachary Karate Club graph\n",
    "G = nx.karate_club_graph()\n",
    "num_nodes = G.number_of_nodes()\n",
    "\n",
    "\n",
    "def plot_graph(G, figsize=(10, 7)):\n",
    "    club_dict = nx.get_node_attributes(G, \"club\")\n",
    "    colors = [\n",
    "        \"lightblue\" if club_dict[node] == \"Mr. Hi\" else \"red\" for node in G.nodes()\n",
    "    ]\n",
    "    plt.figure(figsize=figsize)\n",
    "    nx.draw(\n",
    "        G,\n",
    "        pos=nx.spring_layout(G, seed=42),\n",
    "        with_labels=True,\n",
    "        node_color=colors,\n",
    "        edge_color=\"gray\",\n",
    "        cmap=\"Set2\",\n",
    "    )\n",
    "\n",
    "\n",
    "# plot_graph(G, figsize=(5, 5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../resources/biased_rw.png)\n",
    "\n",
    "in get_alias_edge: \n",
    "- src= t\n",
    "- dst= w"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| node: 0\n",
      "ic| walk: [0, 4, 0, 5, 0, 13, 3, 13, 0, 7]\n",
      "ic| walk: [0, 1, 0, 4, 6, 5, 10, 5, 6, 4]\n",
      "ic| walk: [0, 10, 5, 0, 17, 1, 7, 0, 31, 25]\n",
      "ic| walk: [0, 3, 2, 7, 1, 3, 0, 8, 0, 21]\n",
      "ic| walk: [0, 3, 7, 3, 7, 3, 7, 2, 0, 4]\n",
      "ic| walk: [0, 11, 0, 19, 33, 19, 1, 21, 0, 6]\n",
      "ic| walk: [0, 10, 5, 10, 0, 12, 3, 1, 13, 1]\n",
      "ic| walk: [0, 8, 32, 31, 32, 14, 32, 15, 32, 14]\n",
      "ic| walk: [0, 12, 0, 8, 33, 27, 2, 1, 19, 1]\n",
      "ic| walk: [0, 19, 33, 19, 0, 31, 28, 2, 0, 2]\n"
     ]
    }
   ],
   "source": [
    "def get_alias_edge(G, src, curr, p, q):\n",
    "    \"\"\"Compute transition probabilities for neighbors of 'dst' based on Node2Vec bias.\n",
    "    dst: current node\n",
    "    src: previous node\n",
    "    p: return back to previous node. Lower p means backtracking is more likely.\n",
    "    q: in-out param: explore new nodes (ratio of bfs[breadth-first search] to dfs[depth-first search]).\n",
    "        lower q means more exploration of distant nodes\n",
    "    \"\"\"\n",
    "    unnormalized_probs = []\n",
    "    for neighbor in G[curr]:\n",
    "        if neighbor == src:\n",
    "            weight = 1.0 / p\n",
    "        elif G.has_edge(\n",
    "            neighbor, src\n",
    "        ):  # if neighbor is a neighbor of src (above ex: s1 is neighbor of t)\n",
    "            weight = 1.0\n",
    "        else:\n",
    "            weight = 1.0 / q\n",
    "        unnormalized_probs.append(weight)\n",
    "    norm_const = sum(unnormalized_probs)\n",
    "    normalized_probs = [w / norm_const for w in unnormalized_probs]\n",
    "    return list(G[curr]), normalized_probs\n",
    "\n",
    "\n",
    "def node2vec_walk(G, start, walk_length, p, q):\n",
    "    \"\"\"Generate a random walk starting from the given node.\"\"\"\n",
    "    walk = [start]\n",
    "    while len(walk) < walk_length:\n",
    "        cur = walk[-1]\n",
    "        neighbors = list(G.neighbors(cur))\n",
    "        if len(neighbors) == 0:\n",
    "            break\n",
    "        if len(walk) == 1:\n",
    "            next_node = random.choice(neighbors)\n",
    "        else:\n",
    "            prev = walk[-2]\n",
    "            candidates, probs = get_alias_edge(G, src=prev, curr=cur, p=p, q=q)\n",
    "            next_node = random.choices(candidates, weights=probs, k=1)[0]\n",
    "        walk.append(next_node)\n",
    "    return walk\n",
    "\n",
    "\n",
    "ic.enable()\n",
    "nodes = list(G.nodes())\n",
    "node = nodes[0]\n",
    "ic(node)\n",
    "for i in range(10):\n",
    "    walk = node2vec_walk(G, start=node, walk_length=10, p=1, q=1)\n",
    "    ic(walk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# decompose walk\n",
    "\n",
    "![](../resources/zachary.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| len(neighbors): 16\n",
      "ic| neighbors: [1, 2, 3, 4, 5, 6, 7, 8, 10, 11, 12, 13, 17, 19, 21, 31]\n",
      "ic| next_node: 6\n",
      "ic| walk: [0, 6]\n",
      "ic| len(neighbors): 4\n",
      "ic| neighbors: [0, 4, 5, 16]\n",
      "ic| candidates: [0, 4, 5, 16]\n",
      "ic| probs: [0.2, 0.2, 0.2, 0.4]\n",
      "ic| next_node: 16\n",
      "ic| walk: [0, 6, 16]\n"
     ]
    }
   ],
   "source": [
    "start = 0\n",
    "walk = [start]\n",
    "p = 1\n",
    "q = 0.5\n",
    "walk_length = 2\n",
    "for i in range(walk_length):\n",
    "    cur = walk[-1]\n",
    "    neighbors = list(G.neighbors(cur))\n",
    "    ic(len(neighbors))\n",
    "    ic(neighbors)\n",
    "\n",
    "    if len(neighbors) == 0:\n",
    "        break\n",
    "    if len(walk) == 1:\n",
    "        next_node = random.choice(neighbors)\n",
    "    else:\n",
    "        prev = walk[-2]\n",
    "        candidates, probs = get_alias_edge(G, prev, cur, p, q)\n",
    "        ic(candidates)\n",
    "        ic(probs)\n",
    "        next_node = random.choices(candidates, weights=probs, k=1)[0]\n",
    "    ic(next_node)\n",
    "    walk.append(next_node)\n",
    "    ic(walk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Generate random walks for all nodes\n",
    "\n",
    "# Node2Vec parameters\n",
    "p = 1\n",
    "q = 0.2\n",
    "walk_length = 8\n",
    "num_walks = 20\n",
    "walks = []\n",
    "for _ in range(num_walks):\n",
    "    nodes = list(G.nodes())\n",
    "    random.shuffle(nodes)\n",
    "    for node in nodes:\n",
    "        walk = node2vec_walk(G, node, walk_length, p, q)\n",
    "        walks.append(walk)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "680"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(walks[:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| window_size: 2\n",
      "ic| w: [0, 2, 3, 2, 5, 2, 5]\n",
      "ic| i: 0, target: 0, start: 0, end: 3\n",
      "ic| 'pair', target: 0, j: 1, walk[j]: 2\n",
      "ic| 'pair', target: 0, j: 2, walk[j]: 3\n",
      "ic| i: 1, target: 2, start: 0, end: 4\n",
      "ic| 'pair', target: 2, j: 0, walk[j]: 0\n",
      "ic| 'pair', target: 2, j: 2, walk[j]: 3\n",
      "ic| 'pair', target: 2, j: 3, walk[j]: 2\n",
      "ic| i: 2, target: 3, start: 0, end: 5\n",
      "ic| 'pair', target: 3, j: 0, walk[j]: 0\n",
      "ic| 'pair', target: 3, j: 1, walk[j]: 2\n",
      "ic| 'pair', target: 3, j: 3, walk[j]: 2\n",
      "ic| 'pair', target: 3, j: 4, walk[j]: 5\n",
      "ic| i: 3, target: 2, start: 1, end: 6\n",
      "ic| 'pair', target: 2, j: 1, walk[j]: 2\n",
      "ic| 'pair', target: 2, j: 2, walk[j]: 3\n",
      "ic| 'pair', target: 2, j: 4, walk[j]: 5\n",
      "ic| 'pair', target: 2, j: 5, walk[j]: 2\n",
      "ic| i: 4, target: 5, start: 2, end: 7\n",
      "ic| 'pair', target: 5, j: 2, walk[j]: 3\n",
      "ic| 'pair', target: 5, j: 3, walk[j]: 2\n",
      "ic| 'pair', target: 5, j: 5, walk[j]: 2\n",
      "ic| 'pair', target: 5, j: 6, walk[j]: 5\n",
      "ic| i: 5, target: 2, start: 3, end: 7\n",
      "ic| 'pair', target: 2, j: 3, walk[j]: 2\n",
      "ic| 'pair', target: 2, j: 4, walk[j]: 5\n",
      "ic| 'pair', target: 2, j: 6, walk[j]: 5\n",
      "ic| i: 6, target: 5, start: 4, end: 7\n",
      "ic| 'pair', target: 5, j: 4, walk[j]: 5\n",
      "ic| 'pair', target: 5, j: 5, walk[j]: 2\n"
     ]
    }
   ],
   "source": [
    "window_size = 2\n",
    "embedding_dim = 16\n",
    "num_negative_samples = 5\n",
    "\n",
    "\n",
    "# A walk represents a sequence of nodes traversed in the graph.\n",
    "# For each node (called target) in a walk, the algorithm creates training pairs\n",
    "# with surrounding nodes within a window of size window_size.\n",
    "# window size = 2 means that for each target node,\n",
    "# the algorithm will consider the two nodes before and two nodes after it in the walk.\n",
    "\n",
    "\n",
    "def gen_walk_pairs(walk, window_size):\n",
    "    walk_pairs = []\n",
    "    for i, target in enumerate(walk):\n",
    "        start = max(0, i - window_size)\n",
    "        end = min(len(walk), i + window_size + 1)\n",
    "        ic(i, target, start, end)\n",
    "        for j in range(start, end):\n",
    "            if i != j:\n",
    "                ic(\"pair\", target, j, walk[j])\n",
    "                if walk[j] != target:  # Avoid pairs of the same node\n",
    "                    walk_pairs.append((target, walk[j]))\n",
    "\n",
    "    return walk_pairs\n",
    "\n",
    "\n",
    "ic.enable()\n",
    "w = walks[0]\n",
    "ic(window_size)\n",
    "w = [0, 2, 3, 2, 5, 2, 5]\n",
    "ic(w)\n",
    "walk_pairs = gen_walk_pairs(w, window_size)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(0, 2),\n",
       " (0, 3),\n",
       " (2, 0),\n",
       " (2, 3),\n",
       " (3, 0),\n",
       " (3, 2),\n",
       " (3, 2),\n",
       " (3, 5),\n",
       " (2, 3),\n",
       " (2, 5),\n",
       " (5, 3),\n",
       " (5, 2),\n",
       " (5, 2),\n",
       " (2, 5),\n",
       " (2, 5),\n",
       " (5, 2)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "walk_pairs[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16588"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ic.disable()\n",
    "pairs = []\n",
    "for walk in walks:\n",
    "    walk_pairs = gen_walk_pairs(walk, window_size)\n",
    "    pairs.extend(walk_pairs)\n",
    "\n",
    "pairs = np.array(pairs)\n",
    "len(pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of pairs: 16588\n",
      "Number of unique pairs: 682\n",
      "\n",
      "Top 10 most frequent pairs:\n",
      "Pair (32, 33): 172 occurrences\n",
      "Pair (33, 32): 172 occurrences\n",
      "Pair (33, 2): 125 occurrences\n",
      "Pair (2, 33): 125 occurrences\n",
      "Pair (6, 4): 108 occurrences\n",
      "Pair (4, 6): 108 occurrences\n",
      "Pair (0, 1): 106 occurrences\n",
      "Pair (1, 0): 106 occurrences\n",
      "Pair (5, 6): 103 occurrences\n",
      "Pair (6, 5): 103 occurrences\n",
      "\n",
      "Example lookups:\n",
      "Pair (0, 1) occurs 106 times\n",
      "Pair (1, 0) occurs 106 times\n",
      "\n",
      "Frequency distribution:\n",
      "26 pairs occur 1 time(s)\n",
      "54 pairs occur 2 time(s)\n",
      "58 pairs occur 3 time(s)\n",
      "38 pairs occur 4 time(s)\n",
      "52 pairs occur 5 time(s)\n",
      "32 pairs occur 6 time(s)\n",
      "34 pairs occur 7 time(s)\n",
      "38 pairs occur 8 time(s)\n",
      "32 pairs occur 9 time(s)\n",
      "16 pairs occur 10 time(s)\n",
      "28 pairs occur 11 time(s)\n",
      "4 pairs occur 12 time(s)\n",
      "30 pairs occur 13 time(s)\n",
      "8 pairs occur 14 time(s)\n",
      "6 pairs occur 15 time(s)\n",
      "4 pairs occur 16 time(s)\n",
      "2 pairs occur 17 time(s)\n",
      "2 pairs occur 19 time(s)\n",
      "4 pairs occur 21 time(s)\n",
      "4 pairs occur 22 time(s)\n",
      "4 pairs occur 25 time(s)\n",
      "2 pairs occur 26 time(s)\n",
      "2 pairs occur 27 time(s)\n",
      "2 pairs occur 29 time(s)\n",
      "4 pairs occur 30 time(s)\n",
      "2 pairs occur 31 time(s)\n",
      "6 pairs occur 32 time(s)\n",
      "4 pairs occur 35 time(s)\n",
      "2 pairs occur 36 time(s)\n",
      "2 pairs occur 40 time(s)\n",
      "4 pairs occur 42 time(s)\n",
      "2 pairs occur 43 time(s)\n",
      "6 pairs occur 44 time(s)\n",
      "2 pairs occur 45 time(s)\n",
      "2 pairs occur 46 time(s)\n",
      "2 pairs occur 47 time(s)\n",
      "2 pairs occur 48 time(s)\n",
      "2 pairs occur 49 time(s)\n",
      "4 pairs occur 50 time(s)\n",
      "4 pairs occur 51 time(s)\n",
      "4 pairs occur 52 time(s)\n",
      "8 pairs occur 53 time(s)\n",
      "2 pairs occur 55 time(s)\n",
      "4 pairs occur 56 time(s)\n",
      "6 pairs occur 58 time(s)\n",
      "4 pairs occur 59 time(s)\n",
      "4 pairs occur 61 time(s)\n",
      "2 pairs occur 62 time(s)\n",
      "10 pairs occur 63 time(s)\n",
      "4 pairs occur 64 time(s)\n",
      "8 pairs occur 65 time(s)\n",
      "6 pairs occur 66 time(s)\n",
      "10 pairs occur 67 time(s)\n",
      "6 pairs occur 68 time(s)\n",
      "6 pairs occur 69 time(s)\n",
      "2 pairs occur 70 time(s)\n",
      "2 pairs occur 72 time(s)\n",
      "4 pairs occur 73 time(s)\n",
      "2 pairs occur 75 time(s)\n",
      "4 pairs occur 76 time(s)\n",
      "2 pairs occur 77 time(s)\n",
      "6 pairs occur 78 time(s)\n",
      "2 pairs occur 79 time(s)\n",
      "4 pairs occur 81 time(s)\n",
      "4 pairs occur 82 time(s)\n",
      "2 pairs occur 84 time(s)\n",
      "4 pairs occur 85 time(s)\n",
      "2 pairs occur 86 time(s)\n",
      "2 pairs occur 89 time(s)\n",
      "4 pairs occur 90 time(s)\n",
      "2 pairs occur 95 time(s)\n",
      "2 pairs occur 96 time(s)\n",
      "4 pairs occur 100 time(s)\n",
      "4 pairs occur 103 time(s)\n",
      "2 pairs occur 106 time(s)\n",
      "2 pairs occur 108 time(s)\n",
      "2 pairs occur 125 time(s)\n",
      "2 pairs occur 172 time(s)\n"
     ]
    }
   ],
   "source": [
    "from collections import Counter\n",
    "\n",
    "# Compute pair occurrences\n",
    "pair_counts = Counter(tuple(pair) for pair in pairs)\n",
    "pair_counts\n",
    "# Display the results\n",
    "print(f\"Total number of pairs: {len(pairs)}\")\n",
    "print(f\"Number of unique pairs: {len(pair_counts)}\")\n",
    "print(\"\\nTop 10 most frequent pairs:\")\n",
    "for pair, count in pair_counts.most_common(10):\n",
    "    print(f\"Pair {pair}: {count} occurrences\")\n",
    "\n",
    "# You can also create a dictionary for easy lookup\n",
    "pair_dict = dict(pair_counts)\n",
    "print(f\"\\nExample lookups:\")\n",
    "print(f\"Pair (0, 1) occurs {pair_dict.get((0, 1), 0)} times\")\n",
    "print(f\"Pair (1, 0) occurs {pair_dict.get((1, 0), 0)} times\")\n",
    "\n",
    "# Distribution of pair frequencies\n",
    "freq_distribution = Counter(pair_counts.values())\n",
    "print(f\"\\nFrequency distribution:\")\n",
    "for freq, count in sorted(freq_distribution.items()):\n",
    "    print(f\"{count} pairs occur {freq} time(s)\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pair_dict.get((8, 9))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](../resources/loss_rw.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| num_negative_samples: 5\n",
      "ic| negative_batch: tensor([[ 2, 21,  1, 23, 29],\n",
      "                            [ 1, 20, 32, 11, 21]], device='mps:0')\n"
     ]
    }
   ],
   "source": [
    "ic.enable()\n",
    "ic(num_negative_samples)\n",
    "batch_size = 2\n",
    "negative_batch = torch.LongTensor(\n",
    "    np.random.randint(0, num_nodes, size=(batch_size, num_negative_samples))\n",
    ").to(device)\n",
    "ic(negative_batch);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ic| embedding_dim: 16, num_nodes: 34\n",
      "ic| target.shape: torch.Size([2])\n",
      "    context.shape: torch.Size([2])\n",
      "    negative.shape: torch.Size([2, 3])\n",
      "ic| embed_target.shape: torch.Size([2, 16])\n",
      "    embed_context.shape: torch.Size([2, 16])\n",
      "ic| score: tensor([-0.0855,  0.0556], device='mps:0', grad_fn=<SumBackward1>)\n",
      "ic| log_target: tensor([-0.7368, -0.6658], device='mps:0', grad_fn=<LogBackward0>)\n",
      "ic| embed_negative.shape: torch.Size([2, 3, 16])\n",
      "ic| torch.bmm(embed_negative, embed_target.unsqueeze(2)): tensor([[[ 0.0521],\n",
      "                                                                   [-0.0259],\n",
      "                                                                   [ 0.2595]],\n",
      "                                                          \n",
      "                                                                  [[ 0.1936],\n",
      "                                                                   [-0.0578],\n",
      "                                                                   [ 0.1921]]], device='mps:0', grad_fn=<BmmBackward0>)\n",
      "ic| loss: tensor([2.9679, 2.9189], device='mps:0', grad_fn=<NegBackward0>)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "tensor(2.9434, device='mps:0', grad_fn=<MeanBackward0>)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the Node2Vec Skip-Gram model\n",
    "class Node2Vec(nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim):\n",
    "        super(Node2Vec, self).__init__()\n",
    "        self.in_embeddings = nn.Embedding(num_nodes, embedding_dim)\n",
    "        self.out_embeddings = nn.Embedding(num_nodes, embedding_dim)\n",
    "        nn.init.xavier_uniform_(self.in_embeddings.weight)\n",
    "        nn.init.xavier_uniform_(self.out_embeddings.weight)\n",
    "\n",
    "    def forward(self, target, context, negative):\n",
    "        ic(target.shape, context.shape, negative.shape)\n",
    "        embed_target = self.in_embeddings(target)  # (batch, embedding_dim)\n",
    "        embed_context = self.out_embeddings(context)  # (batch, embedding_dim)\n",
    "        ic(embed_target.shape, embed_context.shape)\n",
    "        score = torch.sum(embed_target * embed_context, dim=1)\n",
    "        ic(score)\n",
    "        log_target = torch.log(torch.sigmoid(score) + 1e-10)\n",
    "        ic(log_target)\n",
    "\n",
    "        embed_negative = self.out_embeddings(\n",
    "            negative\n",
    "        )  # (batch, num_negative, embedding_dim)\n",
    "        ic(embed_negative.shape)\n",
    "        # we could use matmul, but bmm has been specially optimized for batch processing\n",
    "        ic(torch.bmm(embed_negative, embed_target.unsqueeze(2)))\n",
    "        neg_score = torch.bmm(embed_negative, embed_target.unsqueeze(2)).squeeze()\n",
    "        log_negative = torch.sum(torch.log(torch.sigmoid(-neg_score) + 1e-10), dim=1)\n",
    "\n",
    "        loss = -(log_target + log_negative)\n",
    "        ic(loss)\n",
    "        return loss.mean()\n",
    "\n",
    "\n",
    "ic(embedding_dim, num_nodes)\n",
    "model = Node2Vec(num_nodes, embedding_dim).to(device)\n",
    "\n",
    "model.forward(\n",
    "    target=torch.LongTensor([0, 1]).to(device),\n",
    "    context=torch.LongTensor([1, 2]).to(device),\n",
    "    negative=torch.LongTensor([[3, 2, 4], [4, 6, 5]]).to(device),\n",
    ")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Characterize the Spatial Properties of embeddings\n",
    "\n",
    "https://medium.com/data-science-collective/whats-happening-to-embeddings-during-training-338c420705e5\n",
    "\n",
    "To start the study, we first need some indicators or metrics that characterize the spatial properties of embeddings. Among the limited literature, the following measures were selected:\n",
    "\n",
    "- Gini Index: Measures inequality of values, i.e., if the information in the vector is concentrated in a few dimensions.\n",
    "- Vector Entropy: Measures distributional uncertainty that reveals how uniformly the embedding uses its dimensions.\n",
    "- Hoyer Sparsity: Measures how many dimensions are effectively utilized.\n",
    "- Spectral Entropy: Gives a frequency-domain view that reflects how smooth or noisy the embedding is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "\n",
    "def gini(x):\n",
    "    \"\"\"Compute the Gini coefficient of a vector.\"\"\"\n",
    "    x = np.abs(x.flatten()) + 1e-12  # Avoid division by zero\n",
    "    x_sorted = np.sort(x)\n",
    "    n = len(x)\n",
    "    cumulative = np.cumsum(x_sorted)\n",
    "    gini_coeff = (n + 1 - 2 * np.sum(cumulative) / cumulative[-1]) / n\n",
    "    return gini_coeff\n",
    "\n",
    "\n",
    "def vector_entropy(x):\n",
    "    \"\"\"Compute entropy of normalized absolute vector components.\"\"\"\n",
    "    x = np.abs(x.flatten()) + 1e-12\n",
    "    p = x / np.sum(x)\n",
    "    return -np.sum(p * np.log(p))\n",
    "\n",
    "\n",
    "def hoyer_sparsity(x):\n",
    "    \"\"\"Compute Hoyer's sparsity measure of a vector.\"\"\"\n",
    "    x = np.abs(x.flatten())\n",
    "    n = len(x)\n",
    "    l1 = np.sum(x)\n",
    "    l2 = np.sqrt(np.sum(x**2))\n",
    "    if l1 == 0:\n",
    "        return 0.0\n",
    "    return (np.sqrt(n) - (l1 / l2)) / (np.sqrt(n) - 1)\n",
    "\n",
    "\n",
    "def spectral_entropy(E):\n",
    "    \"\"\"Compute spectral entropy from an embedding matrix E (rows = vectors).\"\"\"\n",
    "    # Compute covariance matrix\n",
    "    cov = np.cov(E, rowvar=False)\n",
    "    # Compute eigenvalues\n",
    "    eigvals = np.linalg.eigvalsh(cov)\n",
    "    eigvals = np.clip(eigvals, a_min=1e-12, a_max=None)  # avoid log(0)\n",
    "    p = eigvals / np.sum(eigvals)\n",
    "    return -np.sum(p * np.log(p))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 10, Loss: 1.9654\n",
      "Gini: 0.391, Hoyer's Sparsity: 0.2496, Vector Entropy: 2.505, Spectral Entropy: 2.3241\n",
      "Epoch 20, Loss: 1.9638\n",
      "Gini: 0.397, Hoyer's Sparsity: 0.2579, Vector Entropy: 2.4978, Spectral Entropy: 2.3464\n",
      "Epoch 30, Loss: 1.9648\n",
      "Gini: 0.3998, Hoyer's Sparsity: 0.2608, Vector Entropy: 2.4928, Spectral Entropy: 2.3464\n",
      "Epoch 40, Loss: 1.9664\n",
      "Gini: 0.4003, Hoyer's Sparsity: 0.2618, Vector Entropy: 2.4901, Spectral Entropy: 2.3452\n",
      "Epoch 50, Loss: 1.9711\n",
      "Gini: 0.4071, Hoyer's Sparsity: 0.2687, Vector Entropy: 2.4781, Spectral Entropy: 2.3466\n",
      "Epoch 60, Loss: 1.9587\n",
      "Gini: 0.4054, Hoyer's Sparsity: 0.2688, Vector Entropy: 2.4818, Spectral Entropy: 2.3452\n",
      "Epoch 70, Loss: 1.9676\n",
      "Gini: 0.4135, Hoyer's Sparsity: 0.2762, Vector Entropy: 2.4667, Spectral Entropy: 2.3457\n",
      "Epoch 80, Loss: 1.9597\n",
      "Gini: 0.4097, Hoyer's Sparsity: 0.2741, Vector Entropy: 2.4718, Spectral Entropy: 2.3425\n",
      "Epoch 90, Loss: 1.9582\n",
      "Gini: 0.4154, Hoyer's Sparsity: 0.2807, Vector Entropy: 2.4615, Spectral Entropy: 2.3471\n",
      "Epoch 100, Loss: 1.9641\n",
      "Gini: 0.4176, Hoyer's Sparsity: 0.2833, Vector Entropy: 2.4591, Spectral Entropy: 2.3524\n"
     ]
    }
   ],
   "source": [
    "model = Node2Vec(num_nodes, embedding_dim).to(device)\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "# Training loop\n",
    "num_epochs = 100\n",
    "batch_size = 64\n",
    "num_batches = len(pairs) // batch_size + 1\n",
    "ic.disable()\n",
    "for epoch in range(num_epochs):\n",
    "    np.random.shuffle(pairs)\n",
    "    epoch_loss = 0\n",
    "    for i in range(0, len(pairs), batch_size):\n",
    "        batch = pairs[i : i + batch_size]\n",
    "        ic(batch.shape, batch[:, 0].shape)\n",
    "        target_batch = torch.LongTensor(batch[:, 0]).to(device)\n",
    "        context_batch = torch.LongTensor(batch[:, 1]).to(device)\n",
    "        # Nb: there is no guarantee that the negative samples are actually negative (not connected to target nodes)\n",
    "        # to be perfectly negative, For each target node, sample from nodes that are not its neighbors.\n",
    "        # Not perfect by still works (just noiser.)\n",
    "        negative_batch = torch.LongTensor(\n",
    "            np.random.randint(0, num_nodes, size=(len(batch), num_negative_samples))\n",
    "        ).to(device)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        loss = model(target_batch, context_batch, negative_batch)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        epoch_loss += loss.item()\n",
    "    if (epoch + 1) % 10 == 0:\n",
    "        print(f\"Epoch {epoch + 1}, Loss: {epoch_loss / num_batches:.4f}\")\n",
    "        embeddings = model.in_embeddings.weight.data.cpu().numpy()\n",
    "        gini_score = round(float(np.mean(list(map(gini, embeddings)))), 4)\n",
    "        hoyer_sparsity_score = round(\n",
    "            float(np.mean(list(map(hoyer_sparsity, embeddings)))), 4\n",
    "        )\n",
    "        vector_entropy_score = round(\n",
    "            float(np.mean(list(map(vector_entropy, embeddings)))), 4\n",
    "        )\n",
    "        spectral_entropy_score = round(float(spectral_entropy(embeddings)), 4)\n",
    "        print(\n",
    "            f\"Gini: {gini_score}, Hoyer's Sparsity: {hoyer_sparsity_score}, Vector Entropy: {vector_entropy_score}, Spectral Entropy: {spectral_entropy_score}\"\n",
    "        )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Learned embeddings:\n",
      "Node 0: [-0.49955845 -0.49000397  0.14092606 -1.245069   -1.6117195   0.37397334\n",
      " -0.06207275  0.04993914 -0.42798844  0.16497685 -0.43916345 -0.28619114\n",
      " -0.06202657  0.02914826 -0.3092344  -0.22108014]\n",
      "Node 1: [-0.24376695 -1.0860714  -0.20961866  0.6973329  -1.4602368  -0.2323935\n",
      " -0.32413045  0.7493487   0.9408256  -0.25752327 -1.0320985  -0.23702824\n",
      " -0.6682335   0.3731515  -0.07395089 -0.42440757]\n",
      "Node 2: [-0.44409862  0.10775401 -0.24064426 -0.14203179 -0.7119882  -1.2748002\n",
      "  0.02933224 -0.20920976 -0.2023342   0.32852075 -0.26651543 -1.1047646\n",
      " -0.95364785  0.1063213   0.49263808 -0.29491976]\n",
      "Node 3: [ 0.84697187 -0.3154922  -0.3910283  -1.1903341  -0.99452496 -1.0143274\n",
      " -0.614738    0.83738637  0.29638138 -0.5774908  -0.70874375  0.58410937\n",
      " -1.2204968   0.33784285 -0.41666165  0.03893142]\n",
      "Node 4: [ 0.17620698 -1.5480744  -0.10772036 -0.7095298  -0.85497147 -0.6124968\n",
      "  0.22273368  1.5285254   0.08714233 -0.81456393 -0.10654567  0.22620083\n",
      "  0.95452195 -1.5237402   0.24779171 -1.4046814 ]\n",
      "Node 5: [-0.37512195 -0.87720156  0.68884176 -0.8937013  -1.0141778  -1.3285406\n",
      "  0.3161885   1.7856406   0.32733548  0.31730303 -0.86419356 -0.21839167\n",
      "  0.5358191  -1.7396706   0.0232275   0.53209263]\n",
      "Node 6: [ 0.3582669  -1.3260313   0.40449578 -0.660748   -1.5351902  -0.17437512\n",
      " -0.6125675   0.40311217  0.3615537  -0.56570417  0.00429229 -0.51497424\n",
      " -0.14252615 -3.0233974   0.12259995 -0.02497885]\n",
      "Node 7: [ 0.76282805  0.1801595   1.1527495  -0.22282329 -1.3020046  -0.60869503\n",
      "  0.03374995  1.2172681  -0.10067918 -0.34605893 -0.4279979  -0.62623894\n",
      " -0.6594514   0.06084426 -0.85924155 -1.1235394 ]\n",
      "Node 8: [ 0.20969017  0.08644387 -1.0586436   0.02476766 -0.41313487 -0.01161002\n",
      "  0.06565543  1.5406508   0.4021319  -0.447077    0.12642631 -1.0047567\n",
      "  0.10853866  0.6246745   0.23667905 -0.02928253]\n",
      "Node 9: [-0.6350327   0.1378416  -0.8310279  -0.450599    0.00454717  0.02904567\n",
      "  0.3397812   0.6726661   0.4731102  -1.2394271  -0.5753638   0.39186573\n",
      " -0.84223354  0.283808    0.43144134 -1.4489583 ]\n",
      "Node 10: [-0.13258098 -2.2976358   0.6066203  -0.92695045 -0.1169633  -0.6194804\n",
      "  0.32931095  0.5100673  -0.10173438 -1.2096705  -0.6762699  -1.1560851\n",
      "  0.5499789  -1.3217094  -0.09932317  0.33853835]\n",
      "Node 11: [ 0.1002768  -1.0642167   0.3773428  -0.29756406 -0.6028565  -0.98245066\n",
      " -0.24970108  1.1192733   0.09352506 -0.7275856  -1.390152    0.41072336\n",
      " -0.2651945  -1.130389   -0.22940534 -0.77132833]\n",
      "Node 12: [-0.7777975  -0.07562707  0.8287327  -0.42397544 -1.299248   -0.40194532\n",
      " -0.7311714   0.97632587 -0.3778233  -1.6064686  -1.47497     0.13589333\n",
      "  0.00628227 -0.9154788   0.00782363 -0.9379765 ]\n",
      "Node 13: [-0.15353586 -0.47418895  0.13473201 -0.18199582 -0.34469536 -0.01175636\n",
      "  0.74014056  1.081878    0.3317146  -0.63706     0.21849295 -0.49010813\n",
      " -0.91511536  0.29717746  0.5338044   0.47799188]\n",
      "Node 14: [-1.218619   -0.15999714 -1.1105723  -0.47694045  0.3334509   0.03921337\n",
      " -0.4408897  -0.01419342  2.741788    0.43415362 -0.6220375  -0.6304614\n",
      " -0.86156607  0.20780642 -0.08652412 -1.4526991 ]\n",
      "Node 15: [-0.30341417  0.28286386 -1.3405545  -1.2829258   0.02044032 -0.2022726\n",
      " -0.2442596  -0.11018868  1.5419377   0.8952036   0.05599907 -1.3454878\n",
      " -1.1084054  -0.05910667  0.35653707 -0.50398827]\n",
      "Node 16: [ 0.8125864  -1.3030721  -0.88501066 -0.79557    -2.0032637  -1.2062092\n",
      "  1.1012791   0.25028014  0.0640905  -1.3906721  -1.7269423  -0.57815194\n",
      "  1.1406307  -2.7078948  -0.3733365   0.01336432]\n",
      "Node 17: [ 0.7821972  -0.49051848  0.7867072  -0.94070673 -0.8280273  -0.53898966\n",
      " -0.81055665  1.1077162   0.07126276 -1.2502728  -1.2765819  -0.89565426\n",
      " -0.00534132  0.01742202  0.7534958  -0.24051511]\n",
      "Node 18: [-0.7556846  -0.04183644 -1.3008486  -0.9287598   0.3351859  -0.02767015\n",
      " -0.32736692  0.30206627  1.6213846   0.15362485  0.23785181 -0.738636\n",
      " -1.089726    0.0083723   0.01596336 -0.8564063 ]\n",
      "Node 19: [ 0.55159926  0.33369476 -0.44667113 -0.54244745 -0.6336445  -0.33488104\n",
      "  0.1522121   0.42524546  0.2778903  -0.28007975 -0.56018597 -0.23297115\n",
      " -0.49296698 -0.2576879   1.130688    0.01028741]\n",
      "Node 20: [-1.2900416  -0.01013353 -1.0224162  -0.79131216 -0.21959971  0.6863217\n",
      "  0.06960718  0.11943202  1.2375926   0.23756409  0.35792208 -1.4219759\n",
      " -0.61580634  0.5537892   0.23670264 -0.9387786 ]\n",
      "Node 21: [-0.02476577 -0.77318865 -0.14825149 -0.8507981  -0.26931667 -0.65341514\n",
      " -1.3726327   2.2540147  -0.24654248 -0.85900456 -0.4758257  -0.59537727\n",
      "  0.07778366 -0.6957022   0.18306877 -0.17488898]\n",
      "Node 22: [-0.6658976   0.5534739  -1.0672994  -0.46603194 -0.21235968  0.4654332\n",
      "  0.14390618  0.41248545  1.6734238   0.8201297  -0.9329689  -0.94323987\n",
      " -0.3886864  -0.17518544 -0.07965175 -0.43649504]\n",
      "Node 23: [-0.7093672   0.14995432 -0.48384386 -2.107788    0.3003939  -0.02149936\n",
      "  0.9126527  -0.19918388  1.9224879   0.04804745 -0.11973956 -0.24957158\n",
      "  0.13264501  0.43264672 -0.8842142   0.06191027]\n",
      "Node 24: [-0.97518027  1.0458153  -1.2030878  -0.37837866 -1.4068396  -1.024352\n",
      "  1.2535475   0.3689313   1.2165273  -1.3253722   1.4437325   0.24498007\n",
      " -0.11081957 -0.96082944 -0.83200043 -0.97522664]\n",
      "Node 25: [-1.679365    0.3008465  -1.7415042  -0.30327627 -0.3055115  -2.266623\n",
      "  1.2155237  -0.71426237  0.29289028 -0.91895384  0.00947731 -1.2230337\n",
      " -0.2192473  -0.68141586 -0.8385134   0.01617565]\n",
      "Node 26: [-1.4011903  -0.20176594 -1.4752687  -0.17536773  0.2584416  -0.6013382\n",
      "  0.68122256 -0.04289335  1.3780353   0.9015978  -0.6788139  -1.6809546\n",
      "  0.19460048 -0.34220257  0.53404254 -0.28024954]\n",
      "Node 27: [-0.8823402   0.01826757 -0.65075016 -0.23378515  0.00349547  0.37996498\n",
      " -0.6607121  -0.58958346  1.112288   -1.1837196   0.06020152 -0.7620614\n",
      " -0.8217298  -0.74239975 -0.66268176  0.25118777]\n",
      "Node 28: [-1.6610079   1.0552298   0.4612569  -0.1748114  -0.49152145 -0.6330588\n",
      " -0.3160959   0.7058512   1.3540394  -0.83334774 -0.4556942   0.05371035\n",
      " -0.69732577  0.08225395 -0.4539596   0.6389826 ]\n",
      "Node 29: [-0.28613973  0.09786654 -0.8661516  -0.70752096 -0.47277808  0.3478595\n",
      "  0.46076146  0.00762248  2.6775084   1.0804633   0.50991315 -0.17512162\n",
      " -0.29745805 -0.62881     0.02151935 -1.6385839 ]\n",
      "Node 30: [-0.7092369  -0.03804381 -0.84622127 -0.37452865  0.47755134  0.18100578\n",
      "  0.3201798   1.5108124  -0.2809142  -0.19481288 -0.62134266 -0.1764366\n",
      " -2.0592394  -0.6534077   0.2773562  -0.5652753 ]\n",
      "Node 31: [ 0.7438865  -0.09280881 -0.37719274  0.19469264 -0.5283536   0.09249058\n",
      "  1.2363069  -0.38590688  1.0011355  -0.5043831  -0.5139988  -0.39662755\n",
      " -0.3590809  -0.2229308  -0.6380977  -0.06871652]\n",
      "Node 32: [-0.17583907  0.5967697   0.10883722 -0.7745359   0.15185517  0.02926829\n",
      "  0.2988401  -0.31943104  1.2314465  -1.0912576  -0.2935841  -0.60625273\n",
      " -0.28533962 -0.0285721   1.234432   -0.3134604 ]\n",
      "Node 33: [ 0.10933322  0.52555645  0.4676982  -0.49705365  0.68615425 -0.19051084\n",
      " -0.04307999  0.4272601   0.7357152  -0.2741235  -0.00890624 -1.2475367\n",
      " -0.25393862 -0.20011246 -0.7820151  -0.8930847 ]\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 800x600 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Retrieve learned embeddings\n",
    "embeddings = model.in_embeddings.weight.data.cpu().numpy()\n",
    "print(\"\\nLearned embeddings:\")\n",
    "for node in range(num_nodes):\n",
    "    print(f\"Node {node}: {embeddings[node]}\")\n",
    "\n",
    "# Use PCA to reduce the embeddings to 2D for visualization\n",
    "pca = PCA(n_components=2)\n",
    "embeddings_2d = pca.fit_transform(embeddings)\n",
    "\n",
    "# Create colors list based on club membership: red for 'Mr. Hi', blue for others.\n",
    "colors = []\n",
    "for node in range(num_nodes):\n",
    "    club = G.nodes[node][\"club\"]\n",
    "    colors.append(\"red\" if club == \"Mr. Hi\" else \"blue\")\n",
    "\n",
    "# Plotting the PCA visualization\n",
    "plt.figure(figsize=(8, 6))\n",
    "plt.scatter(embeddings_2d[:, 0], embeddings_2d[:, 1], c=colors)\n",
    "for i in range(num_nodes):\n",
    "    plt.annotate(str(i), (embeddings_2d[i, 0], embeddings_2d[i, 1]), fontsize=9)\n",
    "plt.title(\"PCA Visualization of Node2Vec Embeddings\")\n",
    "plt.xlabel(\"Principal Component 1\")\n",
    "plt.ylabel(\"Principal Component 2\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## gemini\n",
    "\n",
    "Solution suggested by gemini"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import networkx as nx\n",
    "import matplotlib.pyplot as plt\n",
    "import random\n",
    "from collections import defaultdict\n",
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "# Load the Zachary Karate Club graph\n",
    "def load_karate_graph():\n",
    "    \"\"\"\n",
    "    Loads the Zachary Karate Club graph from NetworkX.\n",
    "\n",
    "    Returns:\n",
    "        nx.Graph: The Karate Club graph.\n",
    "    \"\"\"\n",
    "    G = nx.karate_club_graph()\n",
    "    return G\n",
    "\n",
    "\n",
    "# Convert NetworkX graph to adjacency list\n",
    "def graph_to_adj_list(graph):\n",
    "    \"\"\"\n",
    "    Converts a NetworkX graph to an adjacency list representation.\n",
    "\n",
    "    Args:\n",
    "        graph (nx.Graph): The input graph.\n",
    "\n",
    "    Returns:\n",
    "        dict: An adjacency list where keys are nodes and values are lists of neighbors.\n",
    "    \"\"\"\n",
    "    adj_list = defaultdict(list)\n",
    "    for node in graph.nodes():\n",
    "        adj_list[node] = list(graph.neighbors(node))\n",
    "    return adj_list\n",
    "\n",
    "\n",
    "# Generate random walk\n",
    "def generate_random_walk(graph, start_node, walk_length, p, q):\n",
    "    \"\"\"\n",
    "    Generates a random walk starting from a given node.  This implementation\n",
    "    correctly handles the edge weights (p and q) for the walk.\n",
    "\n",
    "    Args:\n",
    "        graph (nx.Graph): The input graph.\n",
    "        start_node (int): The starting node for the random walk.\n",
    "        walk_length (int): The length of the random walk.\n",
    "        p (float): The return parameter.\n",
    "        q (float): The in-out parameter.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of nodes representing the random walk.\n",
    "    \"\"\"\n",
    "    walk = [start_node]\n",
    "    for _ in range(walk_length - 1):\n",
    "        current_node = walk[-1]\n",
    "        neighbors = list(graph.neighbors(current_node))\n",
    "        if not neighbors:\n",
    "            break  # Handle disconnected nodes\n",
    "        if len(walk) == 1:\n",
    "            # Start node case: sample directly from neighbors\n",
    "            next_node = random.choice(neighbors)\n",
    "            walk.append(next_node)\n",
    "        else:\n",
    "            # Subsequent step case: consider p and q\n",
    "            previous_node = walk[-2]\n",
    "            probabilities = []\n",
    "            for neighbor in neighbors:\n",
    "                if neighbor == previous_node:\n",
    "                    probabilities.append(1 / p)  # Return probability\n",
    "                elif graph.has_edge(previous_node, neighbor):\n",
    "                    probabilities.append(1)  # Neighboring node\n",
    "                else:\n",
    "                    probabilities.append(1 / q)  # Non-neighboring node\n",
    "            # Normalize probabilities to sum to 1\n",
    "            probabilities = [prob / sum(probabilities) for prob in probabilities]\n",
    "            # Use the probabilities to select the next node.\n",
    "            next_node = random.choices(neighbors, probabilities)[0]\n",
    "            walk.append(next_node)\n",
    "    return walk\n",
    "\n",
    "\n",
    "# Generate multiple random walks\n",
    "def generate_walks(graph, num_walks, walk_length, p, q):\n",
    "    \"\"\"\n",
    "    Generates multiple random walks for each node in the graph.\n",
    "\n",
    "    Args:\n",
    "        graph (nx.Graph): The input graph.\n",
    "        num_walks (int): The number of random walks per node.\n",
    "        walk_length (int): The length of each random walk.\n",
    "        p (float): The return parameter.\n",
    "        q (float): The in-out parameter.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of lists, where each inner list is a random walk.\n",
    "    \"\"\"\n",
    "    walks = []\n",
    "    nodes = list(graph.nodes())\n",
    "    for _ in range(num_walks):\n",
    "        random.shuffle(nodes)  # Shuffle for each iteration\n",
    "        for node in nodes:\n",
    "            walk = generate_random_walk(graph, node, walk_length, p, q)\n",
    "            walks.append(walk)\n",
    "    return walks\n",
    "\n",
    "\n",
    "# Skip-gram model with negative sampling\n",
    "class SkipGramModel(torch.nn.Module):\n",
    "    \"\"\"\n",
    "    Skip-gram model for learning node embeddings.  This implementation\n",
    "    uses PyTorch and includes proper initialization.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self, num_nodes, embedding_dim):\n",
    "        \"\"\"\n",
    "        Initializes the Skip-gram model.\n",
    "\n",
    "        Args:\n",
    "            num_nodes (int): The number of nodes in the graph.\n",
    "            embedding_dim (int): The dimensionality of the node embeddings.\n",
    "        \"\"\"\n",
    "        super(SkipGramModel, self).__init__()\n",
    "        self.embedding_u = torch.nn.Embedding(\n",
    "            num_nodes, embedding_dim\n",
    "        )  # Target embeddings\n",
    "        self.embedding_v = torch.nn.Embedding(\n",
    "            num_nodes, embedding_dim\n",
    "        )  # Context embeddings\n",
    "\n",
    "        # Initialize embeddings using a small uniform distribution\n",
    "        init_range = 0.5 / embedding_dim\n",
    "        self.embedding_u.weight.data.uniform_(-init_range, init_range)\n",
    "        self.embedding_v.weight.data.uniform_(\n",
    "            -0, 0\n",
    "        )  # init_range, init_range) # Initializing to 0 can sometimes help\n",
    "\n",
    "    def forward(self, center_nodes, context_nodes, negative_samples):\n",
    "        \"\"\"\n",
    "        Computes the forward pass of the Skip-gram model.\n",
    "\n",
    "        Args:\n",
    "            center_nodes (torch.Tensor): Tensor of center node indices.\n",
    "            context_nodes (torch.Tensor): Tensor of context node indices.\n",
    "            negative_samples (torch.Tensor): Tensor of negative sample indices.\n",
    "\n",
    "        Returns:\n",
    "            torch.Tensor: The loss value.\n",
    "        \"\"\"\n",
    "        # Get embeddings for center nodes\n",
    "        u_embeddings = self.embedding_u(center_nodes)  # (batch_size, embedding_dim)\n",
    "\n",
    "        # Get embeddings for context nodes\n",
    "        v_embeddings = self.embedding_v(context_nodes)  # (batch_size, embedding_dim)\n",
    "\n",
    "        # Compute the positive log-likelihood\n",
    "        positive_scores = torch.sum(u_embeddings * v_embeddings, dim=1)  # (batch_size,)\n",
    "        positive_loss = -torch.mean(torch.log(torch.sigmoid(positive_scores)))\n",
    "\n",
    "        # Get embeddings for negative samples\n",
    "        negative_embeddings = self.embedding_v(\n",
    "            negative_samples\n",
    "        )  # (batch_size, num_negative_samples, embedding_dim)\n",
    "\n",
    "        # Compute the negative log-likelihood\n",
    "        negative_scores = torch.bmm(\n",
    "            negative_embeddings, u_embeddings.unsqueeze(2)\n",
    "        ).squeeze(2)  # (batch_size, num_negative_samples)\n",
    "        negative_loss = -torch.mean(torch.log(torch.sigmoid(-negative_scores)))\n",
    "\n",
    "        # Combine positive and negative losses\n",
    "        loss = positive_loss + negative_loss\n",
    "        return loss\n",
    "\n",
    "\n",
    "def generate_negative_samples(walks, num_nodes, window_size, num_negative_samples):\n",
    "    \"\"\"\n",
    "    Generates negative samples for each center node and context node pair.\n",
    "    This version pre-computes the unigram distribution and samples directly\n",
    "    according to that distribution.\n",
    "\n",
    "    Args:\n",
    "        walks (list): A list of random walks.\n",
    "        num_nodes (int): The total number of nodes in the graph.\n",
    "        window_size (int): The context window size.\n",
    "        num_negative_samples (int): The number of negative samples per (center, context) pair.\n",
    "\n",
    "    Returns:\n",
    "        list: A list of tuples, where each tuple contains:\n",
    "            (center_node, context_node, list of negative samples)\n",
    "    \"\"\"\n",
    "    negative_samples = []\n",
    "    node_counts = [0] * num_nodes  # Initialize node counts\n",
    "    for walk in walks:\n",
    "        for node in walk:\n",
    "            node_counts[node] += 1\n",
    "\n",
    "    # Compute the unigram distribution raised to the power of 0.75\n",
    "    total_count = sum(node_counts)\n",
    "    unigram_dist = [(count / total_count) ** 0.75 for count in node_counts]\n",
    "    # Normalize the distribution\n",
    "    unigram_dist = [p / sum(unigram_dist) for p in unigram_dist]\n",
    "\n",
    "    for walk in walks:\n",
    "        for i, center_node in enumerate(walk):\n",
    "            for j in range(\n",
    "                max(0, i - window_size), min(len(walk), i + window_size + 1)\n",
    "            ):\n",
    "                if i != j:\n",
    "                    context_node = walk[j]\n",
    "                    # Generate negative samples, ensuring they are different from the context node\n",
    "                    neg_samples = random.choices(\n",
    "                        range(num_nodes), weights=unigram_dist, k=num_negative_samples\n",
    "                    )\n",
    "                    negative_samples.append((center_node, context_node, neg_samples))\n",
    "    return negative_samples\n",
    "\n",
    "\n",
    "def train_node2vec(\n",
    "    graph,\n",
    "    walks,\n",
    "    embedding_dim,\n",
    "    window_size,\n",
    "    num_negative_samples,\n",
    "    batch_size,\n",
    "    epochs,\n",
    "    learning_rate,\n",
    "    p,\n",
    "    q,\n",
    "    num_workers=0,\n",
    "):\n",
    "    \"\"\"\n",
    "    Trains the Node2vec model. This function incorporates the negative sampling\n",
    "    and training loop, and uses the graph, walks, and p, q parameters.\n",
    "\n",
    "    Args:\n",
    "        graph (nx.Graph): The input graph.\n",
    "        walks (list): A list of random walks.\n",
    "        embedding_dim (int): The dimensionality of the node embeddings.\n",
    "        window_size (int): The context window size.\n",
    "        num_negative_samples (int): The number of negative samples per (center, context) pair.\n",
    "        batch_size (int): The batch size for training.\n",
    "        epochs (int): The number of training epochs.\n",
    "        learning_rate (float): The learning rate.\n",
    "        p (float): The return parameter.\n",
    "        q (float): The in-out parameter.\n",
    "        num_workers (int): Number of workers for data loading (not used in this basic implementation).\n",
    "\n",
    "    Returns:\n",
    "        torch.nn.Module: The trained Skip-gram model.\n",
    "    \"\"\"\n",
    "    # Determine the device to use\n",
    "    device = (\n",
    "        torch.device(\"mps\")\n",
    "        if torch.backends.mps.is_available()\n",
    "        else torch.device(\"cpu\")\n",
    "    )\n",
    "    print(f\"Using device: {device}\")\n",
    "\n",
    "    num_nodes = graph.number_of_nodes()\n",
    "    model = SkipGramModel(num_nodes, embedding_dim).to(device)  # Move model to device\n",
    "    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n",
    "    # Use Binary Cross Entropy Loss (though we calculate it manually for more control)\n",
    "    # criterion = torch.nn.BCEWithLogitsLoss() # Not used, but kept here for reference\n",
    "\n",
    "    negative_samples = generate_negative_samples(\n",
    "        walks, num_nodes, window_size, num_negative_samples\n",
    "    )\n",
    "\n",
    "    # Prepare data for PyTorch (create tensors) outside the loop\n",
    "    center_nodes_all = []\n",
    "    context_nodes_all = []\n",
    "    negative_samples_all = []\n",
    "\n",
    "    for center_node, context_node, neg_samples in negative_samples:\n",
    "        center_nodes_all.append(center_node)\n",
    "        context_nodes_all.append(context_node)\n",
    "        negative_samples_all.append(neg_samples)\n",
    "\n",
    "    center_nodes_tensor = torch.tensor(center_nodes_all, dtype=torch.long).to(\n",
    "        device\n",
    "    )  # Move tensors to device\n",
    "    context_nodes_tensor = torch.tensor(context_nodes_all, dtype=torch.long).to(device)\n",
    "    negative_samples_tensor = torch.tensor(negative_samples_all, dtype=torch.long).to(\n",
    "        device\n",
    "    )\n",
    "\n",
    "    num_samples = len(negative_samples)\n",
    "    for epoch in range(epochs):\n",
    "        # Shuffle the training data at the beginning of each epoch\n",
    "        permutation = torch.randperm(num_samples).to(\n",
    "            device\n",
    "        )  # Move permutation to device\n",
    "        center_nodes_tensor = center_nodes_tensor[permutation]\n",
    "        context_nodes_tensor = context_nodes_tensor[permutation]\n",
    "        negative_samples_tensor = negative_samples_tensor[permutation]\n",
    "        total_loss = 0.0\n",
    "        for i in tqdm(\n",
    "            range(0, num_samples, batch_size), desc=f\"Epoch {epoch + 1}/{epochs}\"\n",
    "        ):\n",
    "            optimizer.zero_grad()\n",
    "            # Get batch\n",
    "            indices = torch.arange(i, min(i + batch_size, num_samples)).to(\n",
    "                device\n",
    "            )  # Move indices to device\n",
    "            batch_center_nodes = center_nodes_tensor[indices]\n",
    "            batch_context_nodes = context_nodes_tensor[indices]\n",
    "            batch_negative_samples = negative_samples_tensor[indices]\n",
    "\n",
    "            # Forward pass\n",
    "            loss = model(\n",
    "                batch_center_nodes, batch_context_nodes, batch_negative_samples\n",
    "            )\n",
    "            total_loss += loss.item()\n",
    "            # Backward pass\n",
    "            loss.backward()\n",
    "            optimizer.step()\n",
    "        print(\n",
    "            f\"Epoch {epoch + 1}/{epochs}, Loss: {total_loss / (num_samples // batch_size)}\"\n",
    "        )\n",
    "    return model\n",
    "\n",
    "\n",
    "def get_node_embeddings(model):\n",
    "    \"\"\"\n",
    "    Gets the node embeddings from the trained model.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The trained Skip-gram model.\n",
    "\n",
    "    Returns:\n",
    "        torch.Tensor: A tensor containing the node embeddings.\n",
    "    \"\"\"\n",
    "    return model.embedding_u.weight.data.cpu().numpy()\n",
    "\n",
    "\n",
    "def visualize_embeddings(embeddings, graph, title=\"Node2vec Embeddings\"):\n",
    "    \"\"\"\n",
    "    Visualizes the node embeddings using a 2D scatter plot.  This version\n",
    "    uses the actual node labels from the Karate Club graph.\n",
    "\n",
    "    Args:\n",
    "        embeddings (numpy.ndarray): The node embeddings.\n",
    "        graph (nx.Graph): The input graph (for getting node labels).\n",
    "        title (str): The title of the plot.\n",
    "    \"\"\"\n",
    "    # Use a simple PCA for dimensionality reduction to 2D\n",
    "    from sklearn.decomposition import PCA\n",
    "\n",
    "    pca = PCA(n_components=2)\n",
    "    reduced_embeddings = pca.fit_transform(embeddings)\n",
    "\n",
    "    # Get the club labels for coloring\n",
    "    club_labels = [graph.nodes[node][\"club\"] for node in graph.nodes()]\n",
    "    colors = [\"red\" if label == \"Mr. Hi\" else \"blue\" for label in club_labels]\n",
    "\n",
    "    plt.figure(figsize=(10, 8))\n",
    "    plt.scatter(reduced_embeddings[:, 0], reduced_embeddings[:, 1], c=colors)\n",
    "\n",
    "    # Add node labels to the plot\n",
    "    for i, node in enumerate(graph.nodes()):\n",
    "        plt.annotate(\n",
    "            str(node),\n",
    "            xy=(reduced_embeddings[i, 0], reduced_embeddings[i, 1]),\n",
    "            xytext=(5, 2),\n",
    "            textcoords=\"offset points\",\n",
    "            fontsize=10,\n",
    "        )\n",
    "\n",
    "    plt.title(title)\n",
    "    plt.xlabel(\"Dimension 1\")\n",
    "    plt.ylabel(\"Dimension 2\")\n",
    "    plt.grid(True)\n",
    "    plt.show()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    # Hyperparameters\n",
    "    embedding_dim = 128\n",
    "    walk_length = 20\n",
    "    num_walks = 10\n",
    "    window_size = 5\n",
    "    num_negative_samples = 5\n",
    "    batch_size = 32\n",
    "    epochs = 50\n",
    "    learning_rate = 0.05  # Increased learning rate\n",
    "    p = 1.0\n",
    "    q = 1.0\n",
    "\n",
    "    # Load graph\n",
    "    karate_graph = load_karate_graph()\n",
    "\n",
    "    # Generate random walks\n",
    "    walks = generate_walks(karate_graph, num_walks, walk_length, p, q)\n",
    "\n",
    "    # Train Node2vec model\n",
    "    model = train_node2vec(\n",
    "        karate_graph,\n",
    "        walks,\n",
    "        embedding_dim,\n",
    "        window_size,\n",
    "        num_negative_samples,\n",
    "        batch_size,\n",
    "        epochs,\n",
    "        learning_rate,\n",
    "        p,\n",
    "        q,\n",
    "    )\n",
    "\n",
    "    # Get node embeddings\n",
    "    node_embeddings = get_node_embeddings(model)\n",
    "\n",
    "    # Visualize embeddings\n",
    "    visualize_embeddings(\n",
    "        node_embeddings, karate_graph, title=\"Node2vec Embeddings (Karate Club)\"\n",
    "    )\n",
    "\n",
    "    # Print the first 5 embeddings\n",
    "    print(\"First 5 Node Embeddings:\")\n",
    "    print(node_embeddings[:5])\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cop-gnn-py3.12 (3.12.8)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
