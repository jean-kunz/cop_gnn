{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.datasets import KarateClub\n",
    "\n",
    "# Load the Zachary Karate Club dataset\n",
    "dataset = KarateClub()\n",
    "data = dataset[0]  # Single graph\n",
    "num_nodes = data.num_nodes  # 34 nodes\n",
    "edge_index = data.edge_index  # Edge list\n",
    "\n",
    "# Construct the similarity matrix S (adjacency matrix)\n",
    "S = torch.zeros((num_nodes, num_nodes))\n",
    "S[edge_index[0], edge_index[1]] = 1  # Undirected graph\n",
    "S = S + torch.eye(num_nodes)  # Add self-loops (optional)\n",
    "\n",
    "\n",
    "# Define the model with embedding lookup\n",
    "class EmbeddingFactorization(nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim):\n",
    "        super(EmbeddingFactorization, self).__init__()\n",
    "        # Embedding layer: each node gets a unique embedding\n",
    "        self.embedding = nn.Embedding(num_nodes, embedding_dim)\n",
    "\n",
    "    def forward(self, node_ids):\n",
    "        # Lookup embeddings for all nodes\n",
    "        Z = self.embedding(node_ids)\n",
    "        return Z\n",
    "\n",
    "\n",
    "# Set up model and optimizer\n",
    "embedding_dim = 16  # Embedding dimension\n",
    "node_ids = torch.arange(num_nodes)  # Node indices [0, 1, ..., 33]\n",
    "model = EmbeddingFactorization(num_nodes=num_nodes, embedding_dim=embedding_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Get embeddings\n",
    "    Z = model(node_ids)\n",
    "\n",
    "    # Reconstructed similarity: Z Z^T\n",
    "    S_hat = torch.matmul(Z, Z.t())\n",
    "\n",
    "    # L2 (Frobenius) loss: ||Z Z^T - S||^2\n",
    "    loss = torch.norm(S_hat - S, p=\"fro\") ** 2\n",
    "\n",
    "    # Backprop\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(200):\n",
    "    loss = train()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Get final embeddings\n",
    "with torch.no_grad():\n",
    "    Z = model(node_ids)\n",
    "    print(\"Final embeddings shape:\", Z.shape)\n",
    "    print(\"Sample embeddings:\\n\", Z[:5])  # First 5 nodes\n",
    "\n",
    "# Evaluate reconstruction error\n",
    "S_hat = torch.matmul(Z, Z.t())\n",
    "reconstruction_error = torch.norm(S_hat - S, p=\"fro\").item()\n",
    "print(f\"Final reconstruction error: {reconstruction_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from torch_geometric.datasets import KarateClub\n",
    "\n",
    "# Load the Zachary Karate Club dataset\n",
    "dataset = KarateClub()\n",
    "data = dataset[0]\n",
    "num_nodes = data.num_nodes  # 34 nodes\n",
    "edge_index = data.edge_index  # Edge list\n",
    "\n",
    "# Construct adjacency matrix (without self-loops for neighborhood computation)\n",
    "A = torch.zeros((num_nodes, num_nodes))\n",
    "A[edge_index[0], edge_index[1]] = 1  # Undirected graph\n",
    "\n",
    "\n",
    "# Compute Jaccard similarity matrix\n",
    "def compute_jaccard_similarity(A):\n",
    "    S = torch.zeros((num_nodes, num_nodes))\n",
    "    for i in range(num_nodes):\n",
    "        for j in range(i, num_nodes):  # Symmetric matrix, compute upper triangle\n",
    "            neighbors_i = set(A[i].nonzero(as_tuple=True)[0].tolist())\n",
    "            neighbors_j = set(A[j].nonzero(as_tuple=True)[0].tolist())\n",
    "            intersection = len(neighbors_i & neighbors_j)\n",
    "            union = len(neighbors_i | neighbors_j)\n",
    "            if union > 0:  # Avoid division by zero\n",
    "                sim = intersection / union\n",
    "                S[i, j] = sim\n",
    "                S[j, i] = sim  # Symmetry\n",
    "    # No self-loops in Jaccard (typically similarity to self is not 1 unless defined)\n",
    "    return S\n",
    "\n",
    "\n",
    "S = compute_jaccard_similarity(A)\n",
    "print(\"Jaccard similarity matrix sample:\\n\", S[:5, :5])\n",
    "\n",
    "\n",
    "# Define the model with embedding lookup\n",
    "class EmbeddingFactorization(nn.Module):\n",
    "    def __init__(self, num_nodes, embedding_dim):\n",
    "        super(EmbeddingFactorization, self).__init__()\n",
    "        self.embedding = nn.Embedding(num_nodes, embedding_dim)\n",
    "\n",
    "    def forward(self, node_ids):\n",
    "        Z = self.embedding(node_ids)\n",
    "        return Z\n",
    "\n",
    "\n",
    "# Set up model and optimizer\n",
    "embedding_dim = 16\n",
    "node_ids = torch.arange(num_nodes)\n",
    "model = EmbeddingFactorization(num_nodes=num_nodes, embedding_dim=embedding_dim)\n",
    "optimizer = torch.optim.Adam(model.parameters(), lr=0.01)\n",
    "\n",
    "\n",
    "# Training function\n",
    "def train():\n",
    "    model.train()\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    # Get embeddings\n",
    "    Z = model(node_ids)\n",
    "\n",
    "    # Reconstructed similarity: Z Z^T\n",
    "    S_hat = torch.matmul(Z, Z.t())\n",
    "\n",
    "    # L2 (Frobenius) loss: ||Z Z^T - S||^2\n",
    "    loss = torch.norm(S_hat - S, p=\"fro\") ** 2\n",
    "\n",
    "    # Backprop\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "    return loss.item()\n",
    "\n",
    "\n",
    "# Train the model\n",
    "for epoch in range(200):\n",
    "    loss = train()\n",
    "    if epoch % 20 == 0:\n",
    "        print(f\"Epoch {epoch}, Loss: {loss:.4f}\")\n",
    "\n",
    "# Get final embeddings\n",
    "with torch.no_grad():\n",
    "    Z = model(node_ids)\n",
    "    print(\"Final embeddings shape:\", Z.shape)\n",
    "    print(\"Sample embeddings:\\n\", Z[:5])\n",
    "\n",
    "# Evaluate reconstruction error\n",
    "S_hat = torch.matmul(Z, Z.t())\n",
    "reconstruction_error = torch.norm(S_hat - S, p=\"fro\").item()\n",
    "print(f\"Final reconstruction error: {reconstruction_error:.4f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cop-gnn-IZjXzcTC-py3.12",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
